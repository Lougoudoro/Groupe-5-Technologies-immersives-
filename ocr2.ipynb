{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d11a7a92-5bb9-4dc0-bcac-ad6a4bc3f6dc",
   "metadata": {},
   "source": [
    "# Import of Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1268,
   "id": "e5f90ca4-ec95-45de-8d3f-003ecfba8288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import stumpy\n",
    "import math\n",
    "from os import listdir\n",
    "from os.path import isfile, join, realpath\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6fadc9-9281-4719-8d8c-97822c15b2b2",
   "metadata": {},
   "source": [
    "## Definition of constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1269,
   "id": "3ee937ba-e001-4a35-ba62-547300811360",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMGPATH = \"sample8.png\"\n",
    "DATASETPATH = \"./dataset/trainingData/\"\n",
    "SETS = [\"majuscules\", \"minuscules\", \"numericals\", \"specials\"]\n",
    "#SETS = [\"t\"]\n",
    "OUTPUTFILE = \"./output.json\"\n",
    "GRADE = 200\n",
    "GRAYSCALE = [0.2989, 0.5870, 0.1140]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8701dfae",
   "metadata": {},
   "source": [
    "## Definition of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1270,
   "id": "6d31b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = None # original image\n",
    "chanels = [] # list of chanels\n",
    "selectedChanel = []\n",
    "grayScaleChanels = [] # list of grayscaled chanels\n",
    "firstLineRow = None # defines the 1st line where a black dot is detected\n",
    "rawLines = dict() # contains rows where black dots are spotted and the column of the black dot. The key is the row and the value is a list of columns\n",
    "spotedLines = [] # start and ending row for each detected line\n",
    "rowsLetters = [] # separated letter boundaries [tl, tr, br, bl]\n",
    "normalizedLetters = [] # normalized letters\n",
    "binarizedChars = [] # binarized matrix of the characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496480a4-23e0-4088-8f7e-14c6930ec721",
   "metadata": {},
   "source": [
    "## Opening the image with Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1271,
   "id": "c03c2bc2-b407-4ee5-a40c-f08f410d8039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=133x65>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = Image.open(IMGPATH)\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6c40f0",
   "metadata": {},
   "source": [
    "## 2.1 Grayscaling\n",
    "### Formula: Y = 0.2989R+0.5870G+0.1140B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17271f15",
   "metadata": {},
   "source": [
    "### 1. Convertion of the image into a list of matrices each one representing R, G, B and alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1272,
   "id": "d81a89b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chanels = np.array(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ffd492",
   "metadata": {},
   "source": [
    "### 2. Function to convert the matrix in to a level of GrayScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1273,
   "id": "b6517cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayScale(matrix, scale):\n",
    "    grayImage = np.zeros(matrix.shape)\n",
    "    R = np.array(matrix[:, :, 0])\n",
    "    G = np.array(matrix[:, :, 1])\n",
    "    B = np.array(matrix[:, :, 2])\n",
    "\n",
    "    R = (R * scale[0])\n",
    "    G = (G * scale[1])\n",
    "    B = (B * scale[2])\n",
    "\n",
    "    Y = R+G+B\n",
    "\n",
    "    for i in range(3):\n",
    "       grayImage[:,:,i] = Y\n",
    "\n",
    "    return Image.fromarray(np.uint8(grayImage))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30048492",
   "metadata": {},
   "source": [
    "#### Converting the list of matrices in to a grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1274,
   "id": "a69baf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grayScaleChanels = grayScale(chanels, [0.2989, 0.5870, 0.1140]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dccbdb",
   "metadata": {},
   "source": [
    "## 2.2 Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1275,
   "id": "2bd0da0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chanel = np.array(grayScaleChanels)[:, :, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b7373b",
   "metadata": {},
   "source": [
    "#### Display of the selected chanel converted into grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1276,
   "id": "283a762f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABBAIUBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APfqKKKKKKKKKKKKKKKKKK4/x/40Pg3TFuliErN0XGa5Gx+J3iTUbdZ4NHTYwyNykVm6r8btR0S48i+06JJPTBrWtviT4lu7SO6h0mJopF3KcHkVTg+Mt/H4htNKv9NEJnlWPcVIHJrf+I/jvWPCUEsmn2UcqRjLPIDxTfg34p1DxZ4fvb3USDItwVGOgGK9Jooooooooork/FPhw69rWlGVd9pEx81cda6aK1ggiSKOFFRAAoCjgV8y/HkKPFy4UDkdB7V7/wCCY0PgnR8ov/Hsvas/xt4Sh186XLHCiy2t0su5VwcCqvxgRW+GOrsVG4RDnHNct+zp/wAidf8A/X1/SvYjIgcIWG49qdRTJJUiGXYKPU05WV1DKQQe4paKKKKKK+X/AI9f8jcn1H8q+gfBH/IkaP8A9ey1v1w3xf8A+SYax/1yryz4Pa1qUHg++0zRrXz7+WfcOcbVxyc0njPQfiD4ctf7aGvXkyglpFz9wV6f8J/GcnjDwzvnybi1xHK56sfWtXxx4vh8J6XHIQHubh/Khjz1Y9K5q08GeI9fshfan4iu7OWcbvsy8iL6V55qfiLxX8KvGENpfalLqNjLyBK3G0nrX0Fo2rW+t6VBf2rhopVzkever9FFFFFfL/x6/wCRuT6j+VfQPgj/AJEjR/8Ar2Wt+uG+L/8AyTDWP+uVcl+zpHH/AMIlfSeWvmfacb8c4x0rvfiOgf4fazkZxbsRXmf7NrH+y9ZXt5yn9Ky/jDe3Nz8U9L0uNhhTE6BjwGPSvTzpvjXjE9pjA/irl/Ffwu1zxlPHPqlxB5ka7VKN2rv/AAN4dk8K+FbbSZZPMaIk7s5610dFFFFFfL/x6/5G5fqP5V9A+CP+RI0f/r2Wt+uG+L//ACTDWP8ArnXKfs6f8idf/wDX1/Su9+Iv/JPtb/69mrzD9m3/AJBus/8AXVf5Vh/HS1udO8e2WvKhMSCMA+pXmvaPAnjCy8W6Bb3MU6NdbP3sQPKn3rd1XU7XSNPku7uZYkUcFj1PYVS8LarNrWhR3s8TRO7MNp9AeK2qKKKKoavNqMFmX0y3jnuM8JI2BXz945+HfxB8Y+IJdQl0y1jU4CoswwK9S8DL4y07SrPTNW0y1jitoxGJEkySBXfDoM9a82+Jun+MPEGlXOjaRp9tJaTja0jyYbFYHwu8OeOvBUMlhPpdqbSaXez+bkius+Idv4s1XSrvStF0+2lguY9jSPJgjPWuI+F/hLx34HuJ4ZNMtTbXDAuTKCRivTPGng608Z6CbK8GyUDcjAdGxXz3J8N/H3hK/c6U0kcTN8rxS43D3Fdf4Y+H3jTxDqEU3izULhLBCGEXmbtxHTiveLeCO2gSGJAqIMAAVJRRRRRRRRRRRRRSFVb7wB+opQABgUUUUUUUUUUUUUUUUUUUUV//2Q==",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=133x65>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image.fromarray(chanel))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee811379",
   "metadata": {},
   "source": [
    "##### finds the first line where a black dot is spotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1277,
   "id": "07bc6c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spotFirstLineRow(chanel, grade):\n",
    "    blackDots = []\n",
    "    for x in range(len(chanel)):\n",
    "        for y in range(len(chanel[x])):\n",
    "            if chanel[x][y] >= grade:\n",
    "                blackDots.append(x)\n",
    "    return min(blackDots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1278,
   "id": "255d3309",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstLineRow = spotFirstLineRow(chanel, GRADE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eeff55",
   "metadata": {},
   "source": [
    "##### removes blank gaps between lines and creates segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1279,
   "id": "dc43d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remblankLines(chanel, grade, startingRow):\n",
    "    blackDottedLines = dict()\n",
    "    for x in range(startingRow, len(chanel)):\n",
    "        blackDots = []\n",
    "        for y in range(len(chanel[x])):\n",
    "            if chanel[x][y] < grade:\n",
    "                blackDots.append(y)\n",
    "        blackDottedLines[x] = blackDots\n",
    "    \n",
    "    copyOfBlackDottedLines = blackDottedLines.copy()\n",
    "    for row, cols in blackDottedLines.items():\n",
    "        if cols==[]:\n",
    "            del copyOfBlackDottedLines[row]\n",
    "    return copyOfBlackDottedLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1280,
   "id": "c255a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawlinesRows = remblankLines(chanel, GRADE, firstLineRow).keys()\n",
    "rawlinesRows = list(rawlinesRows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc1e8b6",
   "metadata": {},
   "source": [
    "##### segments lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1281,
   "id": "bbdf5a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLinePositions(rawLinesRows):\n",
    "    linesRows = []\n",
    "    start = rawLinesRows[0]\n",
    "    end = start\n",
    "    for index, line in enumerate(rawlinesRows):\n",
    "        if index == 0:\n",
    "            continue\n",
    "        if rawlinesRows[index-1]+1 != rawlinesRows[index]:\n",
    "            end = rawlinesRows[index-1]\n",
    "            linesRows.append((start, end))\n",
    "            start = rawlinesRows[index]\n",
    "        if len(rawLinesRows)-1 == index:\n",
    "            linesRows.append((start, rawlinesRows[index]))\n",
    "    return linesRows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1282,
   "id": "efac8430",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotedLines = findLinePositions(rawlinesRows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae393e61",
   "metadata": {},
   "source": [
    "##### spot gaps between letters on a single line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1283,
   "id": "d19dea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spotLineEmptyCols(line, chanel, grade):\n",
    "    cols = []\n",
    "    for col in range(len(chanel[0])):\n",
    "        whiteCols = []\n",
    "        for currentRow in range(line[0], line[1]+1):\n",
    "            if chanel[currentRow][col] > grade:\n",
    "                whiteCols.append(col)\n",
    "        cols.append(whiteCols)\n",
    "        \n",
    "    emptyCols = cols.copy()\n",
    "    for col in cols:\n",
    "        if len(col) < line[1]-line[0] + 1:\n",
    "            emptyCols.remove(col)\n",
    "            \n",
    "    cols = []\n",
    "    for listFromCol in emptyCols:\n",
    "        cols.append(listFromCol[0])\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1284,
   "id": "b7f4f992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((9, 55),\n",
       "  [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132])]"
      ]
     },
     "execution_count": 1284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowsBlankSpaces = []              \n",
    "for line in spotedLines:\n",
    "    empty = spotLineEmptyCols(line, chanel, 128)\n",
    "    rowsBlankSpaces.append((line, empty))\n",
    "\n",
    "rowsBlankSpaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de29ee8a",
   "metadata": {},
   "source": [
    "#### spot letters boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1285,
   "id": "1cc54752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rowLettersBoundaries(rowBlankSpace):\n",
    "    letters = [] # col references of the columns\n",
    "    letterCols = [] # current letter columns\n",
    "    lettersMatrices = [] # set of letters\n",
    "    letterMatrix = [] # top left, top right, bottom right and bottom left of the letter\n",
    "    for col in range(len(chanel[0])):\n",
    "        if col in rowBlankSpace[1]:\n",
    "            if letterCols != []:\n",
    "                letters.append(letterCols)\n",
    "            letterCols = []\n",
    "        else:\n",
    "            letterCols.append(col)\n",
    "\n",
    "    rows = rowBlankSpace[0]\n",
    "    for letterCols in letters:\n",
    "        letterMatrix.append((rows[0], letterCols[0]))\n",
    "        letterMatrix.append((rows[0], letterCols[len(letterCols)-1]))\n",
    "        letterMatrix.append((rows[len(rows)-1], letterCols[len(letterCols)-1]))\n",
    "        letterMatrix.append((rows[len(rows)-1], letterCols[0]))\n",
    "\n",
    "        lettersMatrices.append(letterMatrix)\n",
    "        letterMatrix = []\n",
    "    return lettersMatrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1286,
   "id": "99897a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[(9, 20), (9, 54), (55, 54), (55, 20)],\n",
       "  [(9, 59), (9, 86), (55, 86), (55, 59)],\n",
       "  [(9, 91), (9, 113), (55, 113), (55, 91)]]]"
      ]
     },
     "execution_count": 1286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for rowBlankSpace in rowsBlankSpaces:\n",
    "    rowsLetters.append(rowLettersBoundaries(rowBlankSpace))\n",
    "\n",
    "rowsLetters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef28561",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1287,
   "id": "fa790a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeCharacter(imageArray, top, bottom, left, right, isGray = False, target_size=(15, 15)):\n",
    "    if isGray:\n",
    "        cropped = np.array(imageArray)\n",
    "    cropped = np.array(imageArray)[top:bottom, left:right]\n",
    "    cropped_image = Image.fromarray(cropped)\n",
    "    normalized_image = cropped_image.resize(target_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "    return np.array(normalized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1288,
   "id": "f73998f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for row in rowsLetters:\n",
    "    for letter in row:\n",
    "        normalizedLetters.append(normalizeCharacter(chanel, letter[0][0], letter[2][0], letter[0][1], letter[1][1],))\n",
    "\n",
    "#saves croped characters\n",
    "for index, letter in enumerate(normalizedLetters):\n",
    "    Image.fromarray(letter).save(\"./test/\" + str(index)+\".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe0ac93",
   "metadata": {},
   "source": [
    "### Binarization of the character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1289,
   "id": "3c6ee2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(character, grade):\n",
    "    binarized = np.zeros(character.shape)\n",
    "    for row in range(len(character)):\n",
    "        for col in range(len(character[row])):\n",
    "            if character[row][col]<=grade:\n",
    "                binarized[row][col] = 1\n",
    "    return binarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1290,
   "id": "102f3793",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for index, letter in enumerate(normalizedLetters):\n",
    "    binarizedChars.append(binarize(letter, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac66db1",
   "metadata": {},
   "source": [
    "## 2.3 Recognition of Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fde166b",
   "metadata": {},
   "source": [
    "### creates track sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1291,
   "id": "abf1de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trackSectors(binarizedChar):\n",
    "    width, height = binarizedChar.shape\n",
    "    centerY, centerX = width // 2, height // 2\n",
    "\n",
    "    def pseudoY(centerY, row):\n",
    "        Y = None\n",
    "        Y = centerY - row\n",
    "        if row < centerY:\n",
    "            Y = - Y\n",
    "        return Y\n",
    "    \n",
    "    def psuedoX(CenterX, col):\n",
    "        X = None\n",
    "        X = centerX - col\n",
    "        if row < centerX:\n",
    "            X = - X\n",
    "        return X\n",
    "\n",
    "    distances = []\n",
    "    for row in range(len(binarizedChar)):\n",
    "        Y = pseudoY(centerY, row)\n",
    "        for col in range(len(binarizedChar[row])):\n",
    "            X = psuedoX(centerX, col)\n",
    "            distances.append(np.sqrt((X - centerX)**2 + (Y - centerY)**2))\n",
    "    rad = max(distances)\n",
    "\n",
    "    print(rad)\n",
    "\n",
    "    #size of the tracks\n",
    "    trackSize = rad / 5\n",
    "\n",
    "    sectors = []\n",
    "    for trackNumer in range(5):\n",
    "        sector = []\n",
    "        for row in range(len(binarizedChar)):\n",
    "            Y = pseudoY(centerY, row)\n",
    "            for col in range(len(binarizedChar[row])):\n",
    "                X = psuedoX(centerX, col)\n",
    "                distance = np.sqrt((X - centerX)**2 + (Y - centerY)**2)\n",
    "                angle = math.atan(Y/X)\n",
    "                if trackSize * trackNumer < distance and distance <= trackSize * (trackNumer + 1):\n",
    "                    sector.append(binarizedChar[row][col])\n",
    "        sectors.append(sector)\n",
    "\n",
    "    print(sectors)\n",
    "    return sectors\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41723621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trackSectors(binarized_char):\n",
    "    height, width = binarized_char.shape\n",
    "    center_y, center_x = height // 2, width // 2\n",
    "\n",
    "    # Calculate maximum radius (distance from center to farthest pixel)\n",
    "    max_distance = np.sqrt(center_x**2 + center_y**2)\n",
    "\n",
    "    # Define track size\n",
    "    track_size = max_distance / 5\n",
    "\n",
    "    # Initialize sectors: 5 tracks, each divided into 8 angular sections\n",
    "    sectors = [[0 for _ in range(8)] for _ in range(5)]\n",
    "\n",
    "    for row in range(height):\n",
    "        for col in range(width):\n",
    "            if binarized_char[row][col] == 1:  # Only consider black pixels\n",
    "                # Compute distance and angle\n",
    "                delta_y = row - center_y\n",
    "                delta_x = col - center_x\n",
    "                distance = np.sqrt(delta_x**2 + delta_y**2)\n",
    "                angle = math.atan2(delta_y, delta_x)  # Angle in radians\n",
    "\n",
    "                # Normalize angle to [0, 2π]\n",
    "                if angle < 0:\n",
    "                    angle += 2 * math.pi\n",
    "\n",
    "                # Determine track index (0-4)\n",
    "                track_idx = int(distance // track_size)\n",
    "\n",
    "                # Determine sector index (0-7)\n",
    "                sector_idx = int((angle / (2 * math.pi)) * 8)\n",
    "\n",
    "                # Update the count in the corresponding track-sector\n",
    "                if track_idx < 5:  # Ignore points outside the max radius\n",
    "                    sectors[track_idx][sector_idx] += 1\n",
    "\n",
    "    return sectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1293,
   "id": "6e6bff11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 1, 1, 0, 0, 0, 1, 1], [0, 2, 2, 0, 0, 0, 4, 0], [0, 2, 2, 0, 0, 1, 4, 0], [0, 4, 4, 0, 1, 5, 6, 0], [0, 0, 0, 0, 1, 1, 0, 3]]\n"
     ]
    }
   ],
   "source": [
    "for char in binarizedChars:\n",
    "    sectors = track_sectors(char)\n",
    "    print(sectors)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874f58de",
   "metadata": {},
   "source": [
    "## 2.4 Recognition of Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bf4708",
   "metadata": {},
   "source": [
    "#### data set: https://github.com/MinhasKamal/AlphabetRecognizer/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1294,
   "id": "1661443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectChanel(imagePath):\n",
    "    # opening the image with PILLOW\n",
    "    img = Image.open(imagePath)\n",
    "    # chabels extraction\n",
    "    chanels = np.array(img)\n",
    "    # converting matrices into grayscale\n",
    "    grayScaleChanels = grayScale(chanels, GRAYSCALE)\n",
    "    # selection of a single channel\n",
    "    selectedChanel = np.array(grayScaleChanels)[:, :, 0]\n",
    "    return selectedChanel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bf3e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a472ffd",
   "metadata": {},
   "source": [
    "#### Processing of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898b1dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def charactersProcessor(img):\n",
    "    chanels = [] # list of chanels\n",
    "    selectedChanel = []\n",
    "    grayScaleChanels = [] # list of grayscaled chanels\n",
    "    firstLineRow = None # defines the 1st line where a black dot is detected\n",
    "    rawLines = dict() # contains rows where black dots are spotted and the column of the black dot. The key is the row and the value is a list of columns\n",
    "    spotedLines = [] # start and ending row for each detected line\n",
    "    rowsLetters = [] # separated letter boundaries [tl, tr, br, bl]\n",
    "    normalizedLetters = [] # normalized letters\n",
    "    binarizedChars = [] # binarized matrix of the characters\n",
    "    tracks = []\n",
    "    charTracks = []\n",
    "\n",
    "    selectedChanel = selectChanel(img)\n",
    "    # finds the first row\n",
    "    firstLineRow = spotFirstLineRow(selectedChanel, GRADE)\n",
    "    # detection of raw lines\n",
    "    rawlinesRows = remblankLines(selectedChanel, GRADE, firstLineRow).keys()\n",
    "    rawlinesRows = list(rawlinesRows)\n",
    "    # finds lines positions\n",
    "    spotedLines = findLinePositions(rawlinesRows)\n",
    "    # segment letters of the line\n",
    "    rowsBlankSpaces = []              \n",
    "    for line in spotedLines:\n",
    "        empty = spotLineEmptyCols(line, selectedChanel, 128)\n",
    "        rowsBlankSpaces.append((line, empty))\n",
    "\n",
    "    for rowBlankSpace in rowsBlankSpaces:\n",
    "        rowsLetters.append(rowLettersBoundaries(rowBlankSpace))\n",
    "\n",
    "    # normalize characters\n",
    "    for row in rowsLetters:\n",
    "        for letter in row:\n",
    "            normalizedLetters.append(normalizeCharacter(chanel, letter[0][0], letter[2][0], letter[0][1], letter[1][1],))\n",
    "\n",
    "    # binarize characters\n",
    "    for index, letter in enumerate(normalizedLetters):\n",
    "        binarizedChars.append(binarize(letter, GRADE))\n",
    "\n",
    "        # print(np.array(binarizedChars).shape)\n",
    "\n",
    "    # extract sectors\n",
    "    for char in binarizedChars:\n",
    "        charTracks.append(trackSectors(char))\n",
    "    \n",
    "    return charTracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1296,
   "id": "1d10fe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char2Track(path):\n",
    "    # opening the image with PILLOW\n",
    "    img = Image.open(path)\n",
    "    # chabels extraction\n",
    "    chanel = np.array(img)\n",
    "    # normalize\n",
    "    normalized = normalizeCharacter(chanel, 0, len(chanel), 0, len(chanel[0]), isGray=True)\n",
    "    # binarize\n",
    "    binarizedChar = binarize(normalized, GRADE)\n",
    "    return track_sectors(binarizedChar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1297,
   "id": "491ed408",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = dict()\n",
    "\n",
    "for setPath in SETS:\n",
    "    path = DATASETPATH+setPath\n",
    "    path = realpath(path)\n",
    "    \n",
    "    for folder in listdir(path):\n",
    "        newPath = realpath(path+\"/\"+folder+\"/\")\n",
    "        charTracks = []\n",
    "        for file in listdir(newPath):\n",
    "            fullPath = join(newPath, file)\n",
    "            if isfile(fullPath):\n",
    "                res = char2Track(fullPath)\n",
    "                charTracks.append(res)\n",
    "        chars[folder] = charTracks\n",
    "\n",
    "with open(OUTPUTFILE, \"w\") as f:\n",
    "    json.dump(chars, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c24130",
   "metadata": {},
   "source": [
    "### Matrices Similarity comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1298,
   "id": "40c8fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_hamming_distance(matrixA, matrixB):\n",
    "    \"\"\"\n",
    "    Calculate the total Hamming distance between two 5x8 matrices.\n",
    "    \"\"\"\n",
    "    if len(matrixA) != len(matrixB) or len(matrixA[0]) != len(matrixB[0]):\n",
    "        print(f\"{len(matrixA)}--{len(matrixB)}\")\n",
    "        print(f\"{len(matrixA[0])}--{len(matrixB[0])}\")\n",
    "        raise ValueError(\"Matrices must have the same dimensions.\")\n",
    "    \n",
    "    total_distance = 0\n",
    "    for rowA, rowB in zip(matrixA, matrixB):\n",
    "        total_distance += sum(a != b for a, b in zip(rowA, rowB))\n",
    "    \n",
    "    return total_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "id": "90c9ec3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 37, 'B': 35, 'C': 37, 'D': 37, 'E': 36, 'F': 32, 'G': 36, 'H': 35, 'I': 28, 'J': 33, 'K': 32, 'L': 36, 'M': 37, 'N': 32, 'O': 34, 'P': 32, 'Q': 36, 'R': 34, 'S': 31, 'T': 22, 'U': 36, 'V': 34, 'W': 31, 'X': 31, 'Y': 24, 'Z': 30, 'a': 35, 'b': 34, 'c': 37, 'd': 37, 'e': 32, 'f': 29, 'g': 34, 'h': 36, 'i': 30, 'j': 35, 'k': 32, 'l': 31, 'm': 29, 'n': 39, 'o': 35, 'p': 36, 'q': 37, 'r': 35, 's': 29, 't': 31, 'u': 38, 'v': 31, 'w': 29, 'x': 31, 'y': 28, 'z': 31, '0': 34, '1': 32, '2': 36, '3': 32, '4': 36, '5': 33, '6': 30, '7': 29, '8': 34, '9': 33, '#': 34, '$': 29, '%': 33, '&': 35, '(': 35, ')': 33, ',': 30, ';': 34, '@': 35, 'colon': 35, 'dot': 26, 'exclamation mark': 29, 'question mark': 29, '[': 36, ']': 34, '{': 29, '}': 26}\n",
      "{'A': 32, 'B': 31, 'C': 31, 'D': 30, 'E': 32, 'F': 34, 'G': 32, 'H': 32, 'I': 35, 'J': 35, 'K': 36, 'L': 29, 'M': 35, 'N': 35, 'O': 30, 'P': 36, 'Q': 37, 'R': 35, 'S': 33, 'T': 36, 'U': 30, 'V': 35, 'W': 35, 'X': 35, 'Y': 37, 'Z': 34, 'a': 33, 'b': 27, 'c': 32, 'd': 30, 'e': 34, 'f': 35, 'g': 35, 'h': 26, 'i': 34, 'j': 33, 'k': 32, 'l': 34, 'm': 36, 'n': 28, 'o': 29, 'p': 32, 'q': 35, 'r': 33, 's': 32, 't': 33, 'u': 28, 'v': 36, 'w': 34, 'x': 35, 'y': 37, 'z': 34, '0': 32, '1': 35, '2': 35, '3': 32, '4': 34, '5': 32, '6': 29, '7': 36, '8': 32, '9': 35, '#': 32, '$': 33, '%': 33, '&': 34, '(': 35, ')': 31, ',': 34, ';': 38, '@': 33, 'colon': 33, 'dot': 31, 'exclamation mark': 33, 'question mark': 36, '[': 31, ']': 31, '{': 36, '}': 35}\n",
      "{'A': 34, 'B': 35, 'C': 31, 'D': 30, 'E': 35, 'F': 34, 'G': 31, 'H': 36, 'I': 34, 'J': 32, 'K': 35, 'L': 32, 'M': 35, 'N': 37, 'O': 29, 'P': 30, 'Q': 31, 'R': 34, 'S': 33, 'T': 34, 'U': 31, 'V': 34, 'W': 38, 'X': 35, 'Y': 34, 'Z': 35, 'a': 34, 'b': 32, 'c': 30, 'd': 29, 'e': 33, 'f': 33, 'g': 34, 'h': 33, 'i': 34, 'j': 32, 'k': 32, 'l': 34, 'm': 34, 'n': 31, 'o': 29, 'p': 32, 'q': 32, 'r': 34, 's': 31, 't': 33, 'u': 31, 'v': 33, 'w': 36, 'x': 35, 'y': 34, 'z': 33, '0': 30, '1': 33, '2': 30, '3': 33, '4': 32, '5': 35, '6': 34, '7': 36, '8': 33, '9': 29, '#': 34, '$': 33, '%': 34, '&': 32, '(': 33, ')': 32, ',': 33, ';': 31, '@': 32, 'colon': 33, 'dot': 30, 'exclamation mark': 34, 'question mark': 32, '[': 34, ']': 33, '{': 33, '}': 33}\n",
      "-ThO\n"
     ]
    }
   ],
   "source": [
    "with open(OUTPUTFILE, \"r\") as f:\n",
    "    dataSet = json.loads(f.read())\n",
    "\n",
    "    charsTracks = charactersProcessor(IMGPATH)\n",
    "\n",
    "    result = \"-\"\n",
    "\n",
    "    for charTracks in charsTracks:\n",
    "        charScores = dict()\n",
    "        for charName, tracks in dataSet.items():\n",
    "            scores = []\n",
    "            for track in tracks:\n",
    "                score = matrix_hamming_distance(charTracks, track)\n",
    "                scores.append(score)\n",
    "            charScores[charName] = max(scores)\n",
    "        print(charScores)\n",
    "        s = list(charScores.values())\n",
    "        maxScore = min(s)\n",
    "        index = s.index(maxScore)\n",
    "        result = result + list(charScores.keys())[index]\n",
    "    \n",
    "    print(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1300,
   "id": "d866e72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(matrixA, matrixB):\n",
    "    matrixA = np.array(matrixA,dtype=np.float64)\n",
    "    matrixB = np.array(matrixB,dtype=np.float64)\n",
    "    matrixA = matrixA.flatten()\n",
    "    matrixB = matrixB.flatten()\n",
    "    score = stumpy.match(matrixA, matrixB)\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1305,
   "id": "ab7cbc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat: ThO\n"
     ]
    }
   ],
   "source": [
    "# Load dataset from JSON file\n",
    "with open(OUTPUTFILE, \"r\") as f:\n",
    "    dataSet = json.loads(f.read())\n",
    "\n",
    "# Process input image to extract character tracks\n",
    "charsTracks = charactersProcessor(IMGPATH)\n",
    "\n",
    "result = \"\"\n",
    "\n",
    "# Compare each character track against the dataset\n",
    "for inputTrack in charsTracks:\n",
    "    charScores = {}\n",
    "\n",
    "    # Iterate over dataset characters and their tracks\n",
    "    for charName, datasetTracks in dataSet.items():\n",
    "        scores = []\n",
    "        for datasetTrack in datasetTracks:\n",
    "            score = matrix_hamming_distance(inputTrack, datasetTrack)\n",
    "            #print(max(list(match(inputTrack, datasetTrack)[0])))\n",
    "            #score = max(list(match(inputTrack, datasetTrack).flatten()))\n",
    "            scores.append(score)\n",
    "        \n",
    "        # Use the best score for this character\n",
    "        if scores:\n",
    "            charScores[charName] = max(scores)\n",
    "\n",
    "    # Determine the character with the highest score\n",
    "    if charScores:\n",
    "        bestMatch = min(charScores, key=charScores.get)\n",
    "        result += bestMatch\n",
    "\n",
    "# Print the resulting matched characters\n",
    "print(\"Resultat:\", result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
